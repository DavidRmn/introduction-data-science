{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doree\\AppData\\Local\\Temp\\ipykernel_3296\\2359398814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../data/BikeRentalDaily_train.csv\", sep=\";\", index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"../data/prepared_test.csv\", sep=\";\", index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Minimal Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a baseline linear regression model using the originally provided training \n",
    "dataset with minimal preprocessing and evaluate it with your validation dataset based on accuracies (MAE) and coefficient of determination (ùëÖùëÖ2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W√§hrend unserer ersten Analysen in Task 1 ist uns aufgefallen, dass die Variablen `season` und `hum` fehlende Werte aufweisen. Als Default-Methode und im Sinne von Minimal Preprocessing sollen die Zeilen mit fehlenden Werten entfernt werden.\n",
    "Optionale Methoden zum Umgang mit fehlenden Werten werden im weiteren Verlauf addressiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.dropna()\n",
    "# data_test = data_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desweiteren sollen die Zeilen mit den negativen Werten bei `windspeed` entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_rows_windspeed = data[data['windspeed'] < 0].index\n",
    "\n",
    "negative_rows_windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(negative_rows_windspeed)\n",
    "# auch hier f√ºr test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch die Wochentage mit -1 werden bereinigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wday_by_date(row):\n",
    "    if row[\"weekday\"] > 0:\n",
    "        return row\n",
    "    weekday_shift = { # week starts on Sunday in dataset\n",
    "        6: 0,\n",
    "        0: 1,\n",
    "        1: 2,\n",
    "        2: 3,\n",
    "        3: 4,\n",
    "        4: 5,\n",
    "        5: 6\n",
    "    }\n",
    "    dateformat = \"%d.%m.%Y\"\n",
    "    row[\"weekday\"] = weekday_shift[time.strptime(row[\"dteday\"], dateformat).tm_wday]\n",
    "    return row\n",
    "data_new = data_new.apply(get_wday_by_date, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Baseline Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = 'cnt'\n",
    "\n",
    "features = data_train.drop(columns=[y_label, 'dteday']).columns\n",
    "\n",
    "X = data_train[features]\n",
    "\n",
    "y = data_train[y_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erneuter Split des Trainingsdatensets, um ein Validation Datset zu generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_validation, y_pred).round(2)\n",
    "mae = mean_absolute_error(y_validation, y_pred).round(2)\n",
    "\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Other Options for Missing Value Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the original datasets to address the identified data quality issues e.g. Missing values, Outliers, Features to be transformed (e.g. normalization). Check the effect of each preprocessing step with your validation data set* building additional linear regression models**\n",
    "\n",
    "Einfluss auf R2 und MAE pr√ºfen\n",
    "\n",
    "Hier jetzt zum Beispiel verschiedene Imputation Strategien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir bereits in Task 1 erarbeitet haben, weisen die Spalten `season` und `hum` fehlende Werte auf. Im ersten Schritt haben wir diese Zeilen entfernt. Nun wollen wir die fehlenden Werte imputieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die fehlenden Werte in der Spalte `season` werden anhand des vorliegenden Datums in der entsprechenden Zeile aufgef√ºllt. \n",
    "\n",
    "`get_season_by_date` bestimmt die Jahreszeit anhand eines Datums im Format \"dd.mm\". Sie verwendet das Modul time, um feste Zeitpunkte f√ºr den Beginn der Jahreszeiten (Fr√ºhling, Sommer, Herbst, Winter) festzulegen und vergleicht dann das eingegebene Datum mit diesen Zeitpunkten. Die Funktion gibt eine Ganzzahl zur√ºck, die die entsprechende Jahreszeit repr√§sentiert (1 f√ºr Fr√ºhling, 2 f√ºr Sommer, 3 f√ºr Herbst, 4 f√ºr Winter). Beachte jedoch, dass die Funktion Schwierigkeiten mit dem 29. Februar haben k√∂nnte, wenn keine Jahreszahl angegeben ist, da sie die Schaltjahre nicht ber√ºcksichtigt.\n",
    "Es gibt vier fest definierte Zeitpunkte f√ºr den Beginn jeder Jahreszeit (Fr√ºhling, Sommer, Herbst, Winter). Diese Zeitpunkte sind auf den 20. M√§rz, 20. Juni, 20. September und 20. Dezember festgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.datetime kann nicht mit 29. Feb umgehen, wenn keine Jahreszahl dabei ist\n",
    "import time\n",
    "def get_season_by_date(date: str):\n",
    "    \"\"\"Derive season by date\"\"\"\n",
    "    dateformat = \"%d.%m\"\n",
    "\n",
    "    # Season beginnings\n",
    "    spring = time.strptime(\"20.03\", dateformat)\n",
    "    summer = time.strptime(\"20.06\", dateformat)\n",
    "    autumn = time.strptime(\"20.09\", dateformat)\n",
    "    winter = time.strptime(\"20.12\", dateformat)\n",
    "\n",
    "    date_p = time.strptime(date[:5], dateformat)\n",
    "\n",
    "    if date_p < spring:\n",
    "        return 1\n",
    "    elif spring < date_p < summer:\n",
    "        return 2\n",
    "    elif summer < date_p < autumn:\n",
    "        return 3\n",
    "    elif autumn < date_p < winter:\n",
    "        return 4\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_wrapper(row):\n",
    "    row[\"season\"] = get_season_by_date(row[\"dteday\"])\n",
    "    return row\n",
    "data_new = data.apply(season_wrapper, axis=1)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlende Werte in der Spalte `hum` werden durch den Mittelwert ersetzt. (Wir k√∂nnen √ºber andere Ersetzungswerte noch diskutieren!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"hum\"].fillna(np.mean(data_new[\"hum\"]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Outlier Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einfluss auf R2 und MAE pr√ºfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu sehen, dass die Gesamtanzahl und die Zahl der nicht registrierten Nutzer einen sehr hohen Maximalwert haben. Die Gesamtzahl wird aus registrierten Nutzern + nicht registrierten Nutzern hergeleitet -> Die Outlier werden mittels der `casual` Spalte ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "zscores = stats.zscore(data_new[\"casual\"])\n",
    "thresh = 3.0\n",
    "outliers = data_new[abs(zscores) > thresh]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschlie√üend erfolgt die Entfernung dieser Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_out = data_new.drop(outliers.index, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = pd.concat([data_no_out, pd.get_dummies(data_no_out[\"weekday\"], prefix=\"weekday\", dtype=int)], axis=1)\n",
    "data_d = pd.concat([data_d, pd.get_dummies(data_no_out[\"weathersit\"], prefix=\"weathersit\", dtype=int)], axis=1)\n",
    "data_d.drop(columns=[\"weekday\", \"weathersit\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Application on Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, check your best model and final data preparation, applying them to the test dataset**\n",
    "\n",
    "Nur das beste Model wird am Ende auf dem Test Dataset getestet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Visualization of Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the pre-processed training, validation and test dataset to a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introduction-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
