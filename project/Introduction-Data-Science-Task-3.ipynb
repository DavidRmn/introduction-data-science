{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction-Data-Science Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lena Breitberg, Doreen Mack, David Riethmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn._config import set_config\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, PassiveAggressiveRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "import helpers\n",
    "set_config(transform_output=\"pandas\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/BikeRentalDaily_test.csv', sep=';', index_col='instant')\n",
    "train_data = pd.read_csv('../data/BikeRentalDaily_train.csv', sep=';', index_col='instant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data without Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover = helpers.OutlierRemover(target='cnt', threshold=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no = outlier_remover.fit_transform(test_data)\n",
    "train_data_no = outlier_remover.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sind die finalen Schritte des Preprocessing aus Taks 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_converter = helpers.DatetimeConverter(target_column='dteday', date_format='%d.%m.%Y')\n",
    "season_imputer = helpers.SeasonImputer(target_column='season', date_column='dteday')\n",
    "correct_weekday = helpers.WeekdayMapper(target_column='weekday', date_column='dteday')\n",
    "windspeed_mean_imputer = helpers.ThresholdImputer(target_column='windspeed', threshold=0.0)\n",
    "column_name_transformer = FunctionTransformer(helpers.clean_column_names)\n",
    "weekend_group = helpers.GroupOneHotEncodedTransformer(grouping_info={'weekend': ['weekday_0', 'weekday_6']})\n",
    "weekday_group = helpers.GroupOneHotEncodedTransformer(grouping_info={'weekday': ['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(sparse_output=False, dtype=int), ['season', 'weekday']),\n",
    "    (OneHotEncoder(sparse_output=False, drop='first', dtype=int), ['weathersit']),\n",
    "    (make_pipeline(SimpleImputer(strategy='mean'), StandardScaler()), ['hum']),\n",
    "    (StandardScaler(), ['atemp', 'windspeed', 'leaflets']),\n",
    "    ('drop', ['temp', 'workingday', 'mnth', 'dteday','cnt', 'casual', 'registered']),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = make_pipeline(\n",
    "    datetime_converter,\n",
    "    season_imputer,\n",
    "    correct_weekday,\n",
    "    windspeed_mean_imputer,\n",
    "    feature_transformer,\n",
    "    column_name_transformer,\n",
    "    weekend_group,\n",
    "    weekday_group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(train_data, train_data['cnt'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no, X_validate_no, y_train_no, y_validate_no = train_test_split(train_data_no, train_data_no['cnt'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measures(y_true, y_pred, n_predictors) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate R2, Adjusted R2, and MAE\n",
    "    \n",
    "    Args:\n",
    "        y_true: array-like, True values\n",
    "        y_pred: array-like, Predicted values\n",
    "        n_predictors: int, number of predictors used in the model excluding the intercept\n",
    "        \n",
    "    Returns:\n",
    "        r2: float, R2 score\n",
    "        adjusted_r2: float, Adjusted R2 score\n",
    "        mae: float, Mean Absolute Error\n",
    "    \"\"\"\n",
    "    n = len(y_true)  # Number of observations\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - n_predictors - 1))\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    \n",
    "    measures = {\n",
    "        \"R2\": r2,\n",
    "        \"Adjusted_R2\": adjusted_r2,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse\n",
    "    }\n",
    "\n",
    "    print(f\"R2: {r2:.2f}\")\n",
    "    print(f\"Adjusted R2: {adjusted_r2:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    return measures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualVsPredictChart(true_v, pred_v, model: str = \"\"):\n",
    "    data = {\"Actual\": true_v, \"Predicted\": pred_v}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create a lineplot with Seaborn\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.lineplot(data=df, markers=False)\n",
    "\n",
    "    plt.title(f\"{model} Actual vs. Predicted Values\")\n",
    "    plt.xlabel(\"Data Points\")\n",
    "    plt.ylabel(\"Values\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = performance_measures(y_validate, y_pred, len(baseline.named_steps.linearregression.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualVsPredictChart(y_validate, y_pred, \"Baseline Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Initial Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lazy_predictions(models, predictions, y_validate, n_predictors: int):\n",
    "    \"\"\"\n",
    "    Visualize the predictions from the lazy regressor\n",
    "\n",
    "    Args:\n",
    "        predictions: dict, predictions from the lazy regressor\n",
    "    \"\"\"\n",
    "    models = models.sort_values(by='R-Squared', ascending=False)\n",
    "    for model_name in models.iloc[: 3].index:\n",
    "        y_pred = predictions[model_name].to_list()\n",
    "        _ = performance_measures(y_validate, y_pred, n_predictors)\n",
    "        actualVsPredictChart(y_validate, y_pred, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃ¼r die Evaluierung verschiedener Algorithmen nutzen wir die Bibliothek Lazy Predict bzw. aus dieser Bibliothek den Lazy Regressor. Diese wurde von Shankar Rao Pandala entwickelt. Es handelt sich um eine Wrapper-Bibliothek, die auf vielen verschiedenen Machine Learning Bibliotheken und -Algorithmen basiert.\n",
    "Der Lazy Regressor automatisiert den Auswahlprozess geeigneter Regressionsmodelle, indem eine Vielzahl von Modellen auf den vorliegenden Datensatz angewandt wird. Dieser wird zuvor durch minimales Preprocessing fÃ¼r den Auswahlprozess vorbereitet z.B. mittels Scaling und Imputation. \n",
    "Im Anschluss werden die Modelle anhand der gÃ¤ngigen Metriken, in unserem Fall R-Squared und MAE bewertet. Es ist wichtig zu beachten, dass kein automatisiertes Hyperparamter Tuning durchgefÃ¼hrt wird.\n",
    "Dieses Vorgehen bietet vor allem den Vorteil, dass des gesamte Prozess automatisiert ablÃ¤uft und die Bibliothek sehr einfach anzuwenden ist. ZusÃ¤tzlich wird eine erhebliche Zeitersparnis ermÃ¶glicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_validate = preprocessing_pipeline.fit_transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_regressor = LazyRegressor(verbose=0, ignore_warnings=True, predictions=True)\n",
    "models, predictions = lazy_regressor.fit(X_train, X_validate, y_train, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem DataFrame sind die Metriken der jeweiligen Modelltypen zu sehen. Zu erkennen ist, dass der Typ `GradientBoostingRegressor` nach allen Metriken den hÃ¶chsten Wert fÃ¼r Adjusted R-Squared erzielt. Weitere gut abschneidende Modelltypen sind der `XGBRegressor` und der `ExtraTreesRegressor`. FÃ¼r das Parametertuning werden alle drei Typen nÃ¤her betrachtet, da es sein kÃ¶nnte, dass eines der drei Modelle deutlich besser abschneidet, sobald die Hyperparameter angepasst werden. Den Modelltyp `HistGradientBoostingRegressor` werden wir nicht verwenden, da dieser besonders Ã¤hnliche Eigenschaften aufweist, wie der `GradientBoostingRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf dieser Grafik ist ein Vergleich zwischen tatsÃ¤chlichen und vorhergesagten Daten des `GradientBoostingRegressor` zu sehen. Es ist zu erkennen, dass es einige AusreiÃer nach unten gibt, die das Modell nicht abbilden konnte. Bei dem Wert am rechten Ende des Graphen konnte das Modell dies jedoch sehr gut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_lazy_predictions(models, predictions, y_validate, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no = preprocessing_pipeline.fit_transform(X_train_no)\n",
    "X_validate_no = preprocessing_pipeline.fit_transform(X_validate_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_regressor_no = LazyRegressor(verbose=0, ignore_warnings=True, predictions=True)\n",
    "models_no, predictions_no = lazy_regressor_no.fit(X_train_no, X_validate_no, y_train_no, y_validate_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_lazy_predictions(models_no, predictions_no, y_validate_no, X_train_no.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden probieren wir verschiedene Kombinationen von Hyperparametern fÃ¼r die drei ausgewÃ¤hlten Algorithmen aus, um jeweils die beste Leistung des Modells zu erzielen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = LinearRegression()\n",
    "ransac_regressor = RANSACRegressor(estimator=base_estimator, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'rfe__min_features_to_select': [5, 10, 15],\n",
    "    'ransacregressor__min_samples': [0.5, 0.6, 0.7],  # Proportion of total samples or absolute number\n",
    "    'ransacregressor__max_trials': [50, 100, 150],  # Maximum number of iterations for random sample selection.\n",
    "    'ransacregressor__stop_probability': [0.99, 0.999],  # Confidence level of the algorithm to terminate iterations\n",
    "    'ransacregressor__loss': ['absolute_error', 'squared_error'],  # Loss function to be used\n",
    "}\n",
    "\n",
    "\n",
    "recursive_feature_elimination = RFECV(estimator=ransac_regressor, step=1, cv=5, scoring='r2')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    recursive_feature_elimination,\n",
    "    ransac_regressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=['r2','neg_mean_absolute_error'], refit='r2', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_data, train_data['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggressive Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_aggressive_regressor = PassiveAggressiveRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'rfecv__min_features_to_select': [5, 10, 15],\n",
    "    'passiveaggressiveregressor__C': [0.01, 0.1, 1, 10],\n",
    "    'passiveaggressiveregressor__max_iter': [1000, 1500, 2000],\n",
    "    'passiveaggressiveregressor__tol': [1e-3, 1e-4],\n",
    "    'passiveaggressiveregressor__early_stopping': [True, False],\n",
    "}\n",
    "\n",
    "recursive_feature_elimination = RFECV(passive_aggressive_regressor, n_jobs=-1, scoring='r2', cv=5)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessing_pipeline,\n",
    "    recursive_feature_elimination,\n",
    "    passive_aggressive_regressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=['r2', 'neg_mean_absolute_error'], refit='r2', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_data_no, train_data_no['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Loss**: Loss bezeichnet das VerlustmaÃ. Dieses soll minimiert werden. Wir verwenden die Methode \"quantile\" d.h. die Quantilregression. Hierdurch wird der quantile Fehler minimiert, was zu robusteren Regressionen fÃ¼hren kann. Desweiteren stehen die Methoden squared_error (Minimierung des mittleren quadratischer Fehlers zwischen vorhergesagten und tatsÃ¤chlichen Werten), absolute_error (Minimierung des mittleren absoluten Fehlers zwischen vorhergesagten und tatsÃ¤chlichen Werten) sowie huber (Kombination aus quadratischem und absolutem Fehler) zur Auswahl.\n",
    "- **Alpha**: Der Alpha-Wert beeinflusst die Gewichtung der Residuals in der Quantilregression. Durch die Variation von alpha kann der Fokus auf unterschiedliche Quantile gelegt werden. Wir verwenden eine Liste von Werten von 0.2 bis 0.8 in Schritten von 0.2.\n",
    "- **Criterion**: Hiermit ist das Kriterium gemeint, das zur Auswahl der besten Aufteilung in jedem Entscheidungsbaumknoten verwendet wird. In diesem Fall werden 'friedman_mse' und 'squared_error' verwendet. 'friedman_mse' ist eine verbesserte Version des mittleren quadratischen Fehlers (MSE) fÃ¼r Gradient Boosting.\n",
    "- **Learning Rate**: Die Lernrate steuert, wie stark jeder Baum die vorherigen BÃ¤ume korrigiert. Eine niedrige Lernrate erfordert im Normalfall mehr BÃ¤ume, um den gleichen Effekt zu erzielen, kann jedoch im Gegenzug zu einer besseren Generalisierung fÃ¼hren. Hier werden Werte von 0.1 bis 0.5 in Schritten von 0.1 verwendet.\n",
    "- **Max Depth**: Max Depth meint die maximale Tiefe eines einzelnen Entscheidungsbaums. Eine tiefere Baumstruktur kann zu Overfitting fÃ¼hren, wÃ¤hrend eine flachere Struktur zu Underfitting fÃ¼hren kann. Wir verwenden hier die Werte None, 5 und 10. None bedeutet, dass es keine festgelegte maximale Tiefe gibt.\n",
    "- **Number of Estimators**: Hier wird die Anzahl der BÃ¤ume (SchÃ¤tzer) im Ensemble festgelegt. Eine hÃ¶here Anzahl von BÃ¤umen kann zu einer besseren Modellleistung fÃ¼hren, erfordert jedoch mehr Rechenressourcen. Wir legen die Werte 50, 100 und 200 zur Auswahl fest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of Estimators**: Hier wird die Anzahl der BÃ¤ume (SchÃ¤tzer) im Ensemble festgelegt. Eine hÃ¶here Anzahl von BÃ¤umen kann zu einer besseren Modellleistung fÃ¼hren, erfordert jedoch mehr Rechenressourcen. Wir legen die Werte 50, 100 und 200 zur Auswahl fest.\n",
    "- **Max Depth**: Max Depth meint die maximale Tiefe eines einzelnen Entscheidungsbaums. Eine tiefere Baumstruktur kann zu Overfitting fÃ¼hren, wÃ¤hrend eine flachere Struktur zu Underfitting fÃ¼hren kann. Wir verwenden hier die Werte None, 5 und 10. None bedeutet, dass es keine festgelegte maximale Tiefe gibt.\n",
    "- **Max Leaves**: Max Leaves meint die maximale Anzahl von BlÃ¤ttern in einem Baum und begrenzt das Wachstum der BÃ¤ume.\n",
    "- **Learning Rate**: Die Lernrate steuert, wie stark jeder Baum die vorherigen BÃ¤ume korrigiert. Eine niedrige Lernrate erfordert im Normalfall mehr BÃ¤ume, um den gleichen Effekt zu erzielen, kann jedoch im Gegenzug zu einer besseren Generalisierung fÃ¼hren. Hier werden Werte von 0.1 bis 0.5 in Schritten von 0.1 verwendet.\n",
    "- **Booster**: Hier wird die Art des Boosters, der verwendet wird, festgelegt. \"gbtree\" steht fÃ¼r EntscheidungsbÃ¤ume, \"gblinear\" fÃ¼r lineare Modelle und \"dart\" fÃ¼r Dropout-gestÃ¼tzte EntscheidungsbÃ¤ume.\n",
    "- **Grow Policy**: Die Grow Policy legt die Strategie fÃ¼r das Wachstum der BÃ¤ume fest. 0 steht fÃ¼r \"depthwise\", 1 fÃ¼r \"lossguide\". Bei \"depthwise\" wÃ¤chst der Baum schichtweise, wohingegen \"lossguide\" eine strukturiertere Wachstumsrichtlinie basierend auf dem Verlust verwendet.\n",
    "- **Gamma**: Dieser Paramter gibt an, wie stark ein Baumzweig, basierend auf dem VerlustrÃ¼ckgang, geschnitten wird. Ein hÃ¶herer Gamma-Wert fÃ¼hrt zu konservativerem Pruning.\n",
    "- **Regularization Alpha**: Hiermit ist der L1 Regularisierungsterm auf den Gewichtungen der BlÃ¤tter gemeint. Dieser hilft bei der Vermeidung von Overfitting durch Sparsamkeit.\n",
    "- **Regularization Lambda**: Dieser Parameter meint den L2 Regularisierungsterm auf den Gewichtungen der BlÃ¤tter und hilft bei der Vermeidung von Overfitting durch Schrumpfung der Gewichtungen.\n",
    "- **Metric**: Metric meint die Bewertungsmetrik, die wÃ¤hrend des Trainings verwendet wird. Wir verwenden hier den Mean Absolute Error (skm.mean_absolute_error) als Bewertungsmetrik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ExtraTressRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of Estimators**: Hier wird die Anzahl der BÃ¤ume (SchÃ¤tzer) im Ensemble festgelegt. Eine hÃ¶here Anzahl von BÃ¤umen kann zu einer besseren Modellleistung fÃ¼hren, erfordert jedoch mehr Rechenressourcen. Wir legen die Werte 50, 100 und 200 zur Auswahl fest.\n",
    "- **Criterion**: Criterion wÃ¤hlt das Kriterium aus, das zur Auswahl der besten Aufteilung in jedem Entscheidungsbaumknoten verwendet wird ,z.B. squared_error (mittlerer quadratischer Fehler), absolute_error (mittlerer absoluter Fehler), friedman_mse (verbesserte MSE fÃ¼r Gradient Boosting) oder poisson (Poisson-Regression fÃ¼r ZÃ¤hlvariablen).\n",
    "- **Max Features**: Dieser Paramter definiert die maximale Anzahl der Merkmale, die fÃ¼r die Suche nach der besten Aufteilung in einem Baumknoten verwendet werden, z.B. sqrt (Quadratwurzel der Anzahl der Merkmale) oder log2 (Logarithmus zur Basis 2 der Anzahl der Merkmale):\n",
    "- **Max Depth**: Max Depth meint die maximale Tiefe eines einzelnen Entscheidungsbaums. Eine tiefere Baumstruktur kann zu Overfitting fÃ¼hren, wÃ¤hrend eine flachere Struktur zu Underfitting fÃ¼hren kann. Wir verwenden hier die Werte None, 5 und 10. None bedeutet, dass es keine festgelegte maximale Tiefe gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Auswahl der optimalen Hyperparamter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden alle Hyperparameter definiert. Die Listen enthalten die mÃ¶glichen Werte eines jeden Parameters. Jedes Modell hat verschiedene Hyperarameter zur Auswahl, die bereits vorgestellt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbRegressor = {\n",
    "    \"loss\": ['squared_error'],#, 'absolute_error', 'huber', 'quantile'],\n",
    "    \"alpha\": [0.2*x for x in range(1, 5)],\n",
    "    \"criterion\": ['friedman_mse', 'squared_error'],\n",
    "    \"learning_rate\": [0.1*x for x in range(-2, 3)],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"n_estimators\": [50, 100, 200]\n",
    "}\n",
    "\n",
    "xgbRegressor = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"max_leaves\": [0, 5, 10, 20],\n",
    "    \"learning_rate\": [0.2*x for x in range(1, 5)],\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"grow_policy\": [0, 1],\n",
    "    \"gamma\": [1e-3, 1e-1, 1],\n",
    "    \"reg_alpha\": [1e-3, 1e-1, 1],\n",
    "    \"reg_lambda\": [1e-3, 1e-1, 1],\n",
    "    \"metric\": [mean_absolute_error]\n",
    "}\n",
    "\n",
    "etRegressor = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [None, 3, 5, 10]\n",
    "}\n",
    "\n",
    "features = {\n",
    "    ske.GradientBoostingRegressor: gbRegressor,\n",
    "    xgb.XGBRegressor: xgbRegressor,\n",
    "    ske.ExtraTreesRegressor: etRegressor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe von `GridSearchCV` wird ein Hyperparameter-Tuning fÃ¼r jedes Modell durchgefÃ¼hrt, um jeweils die beste Kombination von Hyperparametern zu finden. Hierbei verwenden wir den negativen Mean Absolute Error als Bewertungsmetrik. Eine automatische Kreuzvalidierung findet ebenfalls statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select_results = pd.DataFrame(columns=[\"model\", \"params\", \"mae\"])\n",
    "\n",
    "\n",
    "for model_type in features:\n",
    "    gs_model = sms.GridSearchCV(estimator=model_type(random_state=1),\n",
    "                                param_grid=features[model_type],\n",
    "                                n_jobs=-1,\n",
    "                                scoring='neg_mean_absolute_error')\n",
    "\n",
    "    gs_model.fit(train_data.drop([\"cnt\"], axis=1), train_data[\"cnt\"])\n",
    "    print(f\"Model type {model_type.__name__}\\nreached MAE of {gs_model.best_score_*-1}\\n Params: {gs_model.best_params_}\")\n",
    "    model_select_results.loc[len(model_select_results)] = [type(gs_model.best_estimator_), gs_model.best_params_, gs_model.best_score_*-1]\n",
    "\n",
    "model_select_results.sort_values(\"mae\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell mit dem besten Ergebnis ist der `XGBRegressor`. Der MAE betrÃ¤gt 670.95 fÃ¼r folgende Hyperparamter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select_results.at[1, \"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion gibt alle mÃ¶glichen, einzigartigen Kombinationen der unabhÃ¤ngigen Variablen aus. Die Liste enthÃ¤lt die hÃ¶chste Anzahl an Features zu Beginn und wird danach immer kÃ¼rzer (Backward Eliminiation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_combinations(features, length):\n",
    "    all_combinations = []\n",
    "    for r in range(1, length + 1):\n",
    "        combinations = itertools.combinations(features, r)\n",
    "        all_combinations.extend(combinations)\n",
    "\n",
    "    # Backwards Elimination\n",
    "    return all_combinations[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion nimmt eine Liste von Indexes auf und gibt die Liste der numerischen Indexes zurÃ¼ck. Dies wird benÃ¶tigt, da die `numpy`-Arrays nach der Skalierung numerische Indexes verwenden. Um auf bestimmte Features zuzugreifen, wird der numerische Index gebraucht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion zur Evaluation einer Feature-Kombination mittels MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_params(features):\n",
    "    reg = Ridge(random_state=1)\n",
    "    reg.fit(train_data[features], train_data[\"cnt\"])\n",
    "\n",
    "    y_pred = reg.predict(validation_data[features])\n",
    "    mae = mean_absolute_error(validation_data[\"cnt\"], y_pred)\n",
    "    coefs = reg.coef_\n",
    "    reg\n",
    "\n",
    "    return dict(features=features,\n",
    "                coefs=coefs,\n",
    "                mae=mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorgehensweise:\n",
    "- Es wird Ã¼ber alle mÃ¶glichen Feature-Kombinationen iteriert und ein `Ridge`-Regressionsmodell erstellt. `Ridge` wird verwendet, da die `LinearRegression` Probleme mit overfitting verursacht.\n",
    "- Die verwendeten Features, die Koeffizienten, sowie der MAE werden in einem DataFrame gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = len(features)\n",
    "feature_list = get_feature_combinations(features, num_of_features)\n",
    "c = 0\n",
    "print(\"Feature combinations\", len(feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt gibt es ca. 4,2 Mio. einzigartige Kombinationen der Features. FÃ¼r jede Kombination wird ein grundlegendes Modell erstellt und dessen MAE, sowie die Parameterkombination gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = [{\"mae\": 0}]\n",
    "num_of_features = len(features)\n",
    "feature_list = get_feature_combinations(features, num_of_features)\n",
    "c = 0\n",
    "print(\"Feature combinations\", len(feature_list))\n",
    "for feature_comb in feature_list:\n",
    "    feature_results.append(eval_model_params(feature_comb))\n",
    "\n",
    "    c+=1\n",
    "\n",
    "    if c % 500 == 0:\n",
    "        print(f\"Evaluating {len(feature_comb)}/{len(features)} feature combinations (No. {c}) - MAE: {feature_results[-1]['mae']}\", end=\"\\r\")\n",
    "\n",
    "feature_results.remove({\"mae\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = pd.DataFrame(feature_results).sort_values(\"mae\", ignore_index=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten AusfÃ¼hrungsergebnisse speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_results.loc[:10000, :].to_csv(\"feature_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenschaften der besten Modelle, sortiert nach dem MAE. Jede Zeile in dem DataFrame ist das Ergebnis eines Modells mit einer einzigartigen Feature-Kombination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features des besten Modells, nach MAE gewertet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results.iat[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Koeffizienten den jeweiligen Features zuordnen zu kÃ¶nnen, erstellen wir dafÃ¼r ein separates DataFrame. Die Koeffizienten sind deshalb wichtig, da sie aussagen, wie wichtig ein Feature fÃ¼r eine genaue Vorhersage ist. Da die Daten bereits skaliert sind, sind alle Werte im Bereich [-1;1] und es gibt keine Gewichtungsunterschiede zwischen den Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dicts = []\n",
    "\n",
    "for idx, row in feature_results.iterrows():\n",
    "    reg_dicts.append({key: value for key, value in zip(row[\"features\"], row[\"coefs\"])})\n",
    "coef_df = pd.DataFrame(data=reg_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchschnittliche Koeffizienten der jeweiligen Features im `Ridge`-Regressionsmodell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkenntnisse:\n",
    "- Die gefÃ¼hlte Temperatur hat einen relativ hohen Einfluss auf die Kundenzahl\n",
    "- An Feiertagen sind ca. 100 Kunden weniger unterwegs\n",
    "- WerbeblÃ¤tter haben einen negativen Einfluss (Vielleicht doch weglassen?)\n",
    "- Eine Preisreduktion hat nur wenig Einfluss auf die Kundenzahl\n",
    "- Im Winter gibt es weitaus weniger Kunden, sonst gibt es keinen signifikaten Unterschied zwischen den Jahreszeiten\n",
    "- Die Wetterbedingungen haben eine entsprechende Auswirkung\n",
    "- Von Montag bis Mittwoch gibt es tÃ¤glich weniger Kunden als an anderen Wochentagen\n",
    "- Je stÃ¤rker die Windgeschwindigkeit, desto weniger FahrrÃ¤der werden gemietet\n",
    "- An Werktagen sind ca. 130 Kunden mehr unterwegs, was darauf hindeutet, dass diese Kunden Arbeitspendler sind\n",
    "- Im Flgejahr gibt tÃ¤glich 1000 Kunden mehr, als im Erstjahr (Kundenzuwachs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koeffiziententabelle speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_df.describe().round(2).T.sort_index().to_csv(\"coefficients.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(mtype, features, params):\n",
    "\n",
    "    fin_model = mtype(random_state=1, **params)\n",
    "\n",
    "    fin_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = fin_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return [mtype.__name__, mae, r2, fin_model, params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_features = feature_results.iat[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_models = pd.DataFrame(columns=[\"modeltype\", \"mae\", \"r2\", \"model\", \"params\"])\n",
    "for idx, row in model_select_results.iterrows():\n",
    "    fin_models.loc[len(fin_models)] = build_model(row[\"model\"], fin_features, row[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_models.loc[1, \"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelltyp**\n",
    "- `sklearn.ensemble.GradientBoostingRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter**\n",
    "- Alpha: `0.2`\n",
    "- Messkriterium: `friedman_mse`\n",
    "- Lernrate: `0.1`\n",
    "- Loss: `squared_error`\n",
    "- Maximale Baumtiefe: `5`\n",
    "- Anzahl Regressoren: `100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verwendete Features**\n",
    "- `yr`\n",
    "- `mnth`\n",
    "- `workingday`\n",
    "- `atemp`\n",
    "- `leaflets`\n",
    "- `weekday_4`\n",
    "- `weekday_5`\n",
    "- `weekday_6`\n",
    "- `season_1`\n",
    "- `season_4`\n",
    "- `weathersit_1`\n",
    "- `weathersit_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(fin_models.at[1, \"model\"], open(\"../models/final_model_optimized.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introduction-data-science",
   "language": "python",
   "name": "introduction-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
